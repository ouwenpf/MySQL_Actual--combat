# 常用备份工具

[名词解释](https://blog.csdn.net/joe_007/article/details/7014381)  
[参考资料](https://www.jianshu.com/p/4e3edbedb9a8)

## mysqldump工具
mysqldump --single-transaction --master-data=2   
一定需要加上以上2个参数，但是不支持非事务表，如果不加入此参数备份是数据不一致性的备份或者是无效的备份
```
mysqldump --single-transaction --master-data=2 
-A：备份所有库
-B：备份单个库(生成create database语句)，-B database_name1 database_name2 ..
-d：只导出表结构  mysqldump -d  --triggers-false
-t：只导出数据  mysqldump  --single-transaction --triggers-false -t
-n: 如果使用了-B参数，在备份文件中不为每个库添加create database 语句
--where="1=1 limit 10000"：导出前10000行数据
-x：备份非事务表，锁定所有的表进行备份，对业务有影响，但是为了数据一致性必须这样做
-R:表示导出function和procedure和触发器,常用-ntd -R -E(--triggers=false)默认导出触发器  mysqldump  -Rntd  --triggers-false
-E:表示只导出事件  mysqldump  -Entd  --triggers-false
--triggers:只导出触发器 mysqldump  -ntd  --triggers
mysqldump最佳实践：
mysqldump --single-transaction --master-data=2  --set-gtid-purged=off -A |gzip > $dbname-$port-`date +%Y%m%d`.sql.gz
gzip：也可以换成bzip2或xz更高效的压缩比工具
zact test.sql.gz|mysql -p123456 test

以上备份作为主从关系数据一致性得到保障，如果不是这样的关系备份需要加上以下参数
--set-gtid-purged=off然后再导入数据
https://juejin.cn/post/7056604185042616350#heading-3

备份库：
mysqldump -S /tmp/mysql3306.sock --single-transaction --master-data=2 --set-gtid-purged=OFF -B `mysql -S  /tmp/mysql3306.sock  -e 'show databases;'|egrep -v 'information_schema|performance_schema|mysql|sys'|sed '1d'` |gzip >  fulldata_name-$port-`date +%Y%m%d`.sql.gz
备份数据库+存储过程函数-触发器
mysqldump -S /tmp/mysql3306.sock --single-transaction --master-data=2 --set-gtid-purged=OFF -R -B `mysql -S  /tmp/mysql3306.sock  -e 'show databases;'|egrep -v 'information_schema|performance_schema|mysql|sys'|sed '1d'` |gzip >  fulldata_name-$port-`date +%Y%m%d`.sql.gz
只备份存储过程函数-触发器
mysqldump -S /tmp/mysql3306.sock --single-transaction --master-data=2 --set-gtid-purged=OFF -ntd -R -B `mysql -S  /tmp/mysql3306.sock  -e 'show databases;'|egrep -v 'information_schema|performance_schema|mysql|sys'|sed '1d'` |gzip >  fulldata_name-$port-`date +%Y%m%d`.sql.gz

```

### mysqldump工具执行原理
流程如下：   
```
1. flush tables;  medata lock如果拿不到说明有长事务或者DDL
2. flush table with read lock; 关闭所有的表，并给所有数据库的表加上一个global read lock  
							   这个对于backup操作来说很有用，加锁之后
							  需要注意:如果ftwrl前面有运行的慢sql,由于慢sql阻塞了当前ftwrl,即使当前ftwrl退出了,后面也会有影响,直到慢sql执行完毕
3. set session transaction isolation level repeatable read;(可重复读)
4. start transaction;事务开始,起始点
5. get gtid;
6. show master status;
7. unlock tables;

8. savepoint sp(事务内的断点);
9. show tables;
	show create table tb_name1;
	select * from tb_name1;
10. rollback to savepoin sp;每次此操作是为了备份过程中释放备份过程中占用的内存，减少内存的开销
	show create table tb_name2;
	select * from tb_name2;
......
11. rollback to savepoin sp;
12. release savepoin sp;
注意8.0中引入了lock instance for backup (只是锁住MyISAM引擎,Frm,CSV文件)，不能操作DDL，写入数据是可以的，对于逻辑备份没有作用还是和5.7是一样的原理，对于物理备份xtrabackup是有作用，不要搞混了,只是更加轻量级相对于flush table with read lock.

所有备份在一个连接里面进行，单进程，所有mysqldump备份时间很长，效率不高

可以使用pathon或者其它语言编写多线程进行备份，思路如下：
master_thread
		flush tables;
		FTWRL
	 t1:set session transaction isolation level repeatable read;
	 	show master status;
		unlock tables;
	 t3:unlock tables;
	 
worker_thread
	 t2 c1:set session transaction isolation level repeatable read;
	 t2 c1:start transcation;
	 
	 t4: 
	 	savepoint sp;
		...
		rollback to savepoin sp;
	 
worker_thread
	 t2 c2:set session transaction isolation level repeatable read;
	 t2 c2:start transcation;

	 t4: 
	 	savepoint sp;
		...
		rollback to savepoin sp;
	 

	 
worker_thread
	 t2 c3:set session transaction isolation level repeatable read;
	 t2 c3:start transcation;
	 
	 t4: 
	 	savepoint sp;
		...
		rollback to savepoin sp;	 

worker_thread
	 t2 c4:set session transaction isolation level repeatable read;
	 t2 c4:start transcation;
	 
	 t4: 
	 	savepoint sp;
		...
		rollback to savepoin sp;
```

### xtrabackup备份及原理
[下载地址](https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/)   
[压缩备份](https://www.percona.com/doc/percona-xtrabackup/LATEST/innobackupex/streaming_backups_innobackupex.html)  
xtrabackup备份流程  
![](images/9-常用备份工具/常用备份工具1.jpg)  
![](images/9-常用备份工具/常用备份工具2.jpg)  
![](images/9-常用备份工具/备份过程3.jpg) 

###xtrabackup最小化授权
[参考资料](https://www.percona.com/doc/percona-xtrabackup/8.0/using_xtrabackup/privileges.html)  
正常授权只需要SELECT,RELOAD,LOCK TABLES,SUPER,BACKUP_ADMIN,PROCESS,REPLICATION (针对8.0)

```
5.7版本备份
备份：
	innobackupex  --defaults-file=/data/mysql/mysql3306/my.cnf -S /tmp/mysql3306.sock    --no-timestamp /data/backup   
 	
应用日志(crash-recovery)
	  innobackupex --apply-log /data/backup/2019-02-25_12-54-58/
	  --user-memory=1G
	  --user-memory = innodb_buffer_pool_size
还原：
	innobackupex   --defaults-file=/data/mysql/mysql3306/my.cnf --copy-back|--move-back  /data/backup/2019-02-25_12-54-58   
删除ib_logfile*文件 才可以拷贝
如果此命令拷贝不了，直接cp /data/backup/2019-02-25_12-54-58 /data/mysql/mysql3306/data/



8.0备份略有不同参数
备份：
/application/xtrabackup-8.0.30/bin/xtrabackup  --user=dba_backup --password=123456 --host=127.0.0.1  --port=3306  --parallel=8 --use-memory=2G   --target-dir=/data/backup/`date +%F\%H%M%S`  --backup 

/application/xtrabackup-8.0.30/bin/xtrabackup  --user=dba_backup --password=123456 --host=127.0.0.1  --port=3306  --parallel=8 --use-memory=2G   --target-dir=/data/backup/`date +%F\%H%M%S`  --backup 2>back.log

 
	
	
backup-lock-timeout 能够在存在备份锁等待的情况下 超过参数指定时间后，放弃备份任
务，优先保障实例上面SQL命令的执行。
kill-long-queries-timeout 能够在有Long-quer阻塞的情况下 杀掉长查询的sessio
n，优先保障备份任务的执行。


还原:
	xtrabackup   --target-dir=/data/backup8  --prepare
	xtrabackup    --defaults-file=/data/mysql/mysql3306/my.cnf    -ubackup -p123456    -S  /tmp/mysql3306.sock   --target-dir=/data/backup  --copy-back|--move-back 
	删除ib_logfile*文件 才可以拷贝
如果此命令拷贝不了，直接cp /data/backup/2019-02-25_12-54-58 /data/mysql/mysql3306/data/

xtrabackup8.0通过访问performance_schema.log_status来实现一致性的备份,摒弃了ftwrl重量级全局锁的弊端,如果有混合引擎采用lock instance for backup来实现一致性备份,相对也比较轻量级
所以在线上的环境不要随意访问performance_schema.log_status表,会导致性能下降(由于不能写入binlog在访问这个表)
```

加密备份:
openssl rand -base64 24
--encrypt=AES256 --encrypt-key=$KEY
--decrypt=AES256 --encrypt-key=$KEY

xtrabackup    --defaults-file=/data/mysql/mysql3306/my.cnf    -ubackup -p123456    -S  /tmp/mysql3306.sock --encrypt=AES256  --encrypt=AES256 --encrypt-key=$KEY   --target-dir=/tools/backup  --backup
xtrabackup   --target-dir=/data/backup  --decrypt=AES256 --encrypt-key=$KEY --prepare

+0yFVV+5fWeFjOj1rAcG3WAR5KGPGnj9
### 位置点信息不一致
xtrabackup_binlog_info：数据从show master status中读取  
xtrabackup_binlog_pos_innodb：数据从redo log last commit filename和postion中读出  

远程压缩备份:
xtrabackup    --defaults-file=/data/mysql/mysql3306/my.cnf    -ubackup -p123456    -S  /tmp/mysql3306.sock    --backup   --stream=xbstream  --target-dir=./ |ssh 10.0.8.11  "cat - >/tools/backup/db3306_`date +%Y%m%d`.xbstream"
多线程stream方式备份
xtrabackup    --defaults-file=/data/mysql/mysql3306/my.cnf    -ubackup -p123456    -S  /tmp/mysql3306.sock    --backup  --compress --compress-threads=8   --parallel=4 --stream=xbstream  --target-dir=./ |ssh 10.0.8.11  "cat - >/tools/backup/db3306_`date +%Y%m%d`.xbstream"

备份完后解压:
xbstream -x <  backup.xbstream


如果出现位置点不一样
- 备份之前flush logs
- 事务引擎和非事务引擎混合
- 备份之前reset master
xtrabackup    --defaults-file=/data/mysql/mysql3306/my.cnf    -ubackup -p123456    -S  /tmp/mysql3306.sock --encrypt=AES256  --encrypt=AES256 --encrypt-key=$KEY   --backup  --stream=tar ./|ssh 10.0.8.11 "gzip - >/tools/backup/db3306_`data +%Y%m%d.gz`"


### mysql8.0新特性clone plugin
[参考资料](https://dev.mysql.com/doc/refman/8.0/en/clone-plugin-installation.html)  

```
添加如下参数
[mysqld]
plugin-load-add=mysql_clone.so
sql_require_primary_key=on;
explicit_defaults_for_timestamp=on;
mysqlx_port=33060;

1. 本地克隆
create user clone_user@'%' identified by '123456';
grant backup_admin on *.*  to clone_user@'%' ;
clone local data directory='/data/mysql/mysql3307/data'; 注意:data目录不能存在,上级目录需要mysql用户权限
克隆完后使用mysqld_safe  --defaults-file=/data/mysql/mysql3307/my.cnf  &启动实例即可,官方推荐使用mysqld_safe启动

远程克隆:

1.确保捐赠者和接受者都安装了克隆插件
2. 捐赠者授权10.0.8.11
create user clone_user@'%' identified by '123456';
grant backup_admin on *.*  to clone_user@'%' ;
3. 接受者授权10.0.8.12
create user clone_user@'%' identified by '123456';
grant CLONE_ADMIN on *.*  to clone_user@'%';
4.接受者设置捐赠者列表清单
mysql -uclone_user -h10.0.0.8.12 
SET GLOBAL clone_valid_donor_list = '10.0.8.11:3306';
5. 接受者开始拉取克隆捐赠者数据
clone INSTANCE FROM clone_user@'10.0.8.11':3306  IDENTIFIED BY '123456';

注意:使用clone_plugin安装官方说明都使用mysqld_safe  --defaults-file=/data/mysql/mysql3307/my.cnf  &启动,远程克隆后等待服务自动重启即可
原来的data目录,自动备份被daba.bak
```

### 表空间传输

```
限制条件:
1. 不能有主外键
2. 

flush table tabname for export;
cp tabname.ibd  tabname.cfg 
unlock tables;


alter table tabname discard tablespace; 千万不要在主库上面执行,慎用
cp tabname.ibd  tabname.cfg ;注意mysql权限       
alter table tabname import tablespace;


```

### mydumper和myload
```sh
https://github.com/mydumper/mydumper/releases git下载路径
-- 导出所有数据库，不包含mysql|information_schema|performance_schema|sys。且对trigger(G)、routines(R)、events(E)也导出，进行数据压缩(c)，且8线程(t)导出

-o不指定文件路径 默认默认export-YYYYMMDD-HHMMSS
-m 只备份数据
-d 只备份表结构
-x --regex正则表达式
-c 压缩备份


# 全库备份，mydumper由于不能指定备份多个库，需要使用正则表达式
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -x '^(?!(mysql|information_schema|performance_schema|sys))'   -G -R -E -c  -t 8 -o mysql_backup

# 备份多个库
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -x 'db1|db2'  -G -R -E -c  -t 8 -o mysql_backup

# 备份单个库
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -B dbname -t 8 -c -o mysql_backup

# 备份表
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -B dbname -T t1,t2..    -o /root/mydumper

# 只备份表结构
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -B dbname -d -t 8  -c -o mysql_backup
# 只备份数据
./mydumper  -h 127.0.0.1  -u root  -p 123456 -P 3306 -B dbname -m -t 8  -c -o mysql_backup
# 参考连接
https://www.cnblogs.com/lijiaman/p/14799813.html

# myloader导入
 ./myloader  -S /data/mysql/mysql3307/tmp/mysql3307.sock  -o  -e -d export-20230524-155655/
-o：在恢复时，如果表存在，则先删除
-e：相当于这个参数sql_log_bin 
-d：备份目录

```

### postgres备份工具
```sh
PostgreSQL 协议连接方式：
PGPASSWORD=abc psql -h 127.0.0.1 -U abc -p 47001 -d postgres
psql postgres://abc:abc@127.0.0.1:47001/postgres

# 备份某个库
PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres  --no-shard-option --no-owner --no-privileges --quote-all-identifiers > postgres_`date +%Y%m%d`.sql

PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres --no-owner --no-privileges --quote-all-identifiers> postgres_`date +%Y%m%d`.sql
# 只备份表结构
PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres --no-shard-option --no-owner --no-privileges --quote-all-identifiers -s> postgres_`date +%Y%m%d`.sql

PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres   --no-owner --no-privileges --quote-all-identifiers -s> postgres_`date +%Y%m%d`.sql

# 备份多个表结构,如果备份指定的库下面有多个schema,需要使用schema_name.tab 默认public不需要
PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres  --no-shard-option --no-owner --no-privileges --quote-all-identifiers -t schema1.t1 -t schema1.t2 .. -s> postgres_`date +%Y%m%d`.sql
# 只备份数据
PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d  postgres --no-shard-option --no-owner --no-privileges --quote-all-identifiers -a> postgres_`date +%Y%m%d`.sql

PGPASSWORD=abc pg_dump -h127.0.0.1 -p47001  -U abc -d postgres --no-owner --no-privileges  --quote-all-identifiers -a> postgres_`date +%Y%m%d`.sql


# 备份用户权限
PGPASSWORD=abc pg_dumpall -h 192.168.0.176 -U abc -p 47001 --globals-only > role.sql

-d: 指定数据库
-s：只导出表结构
-a：只导出数据
-t：指定某个表
-n：指定模式
-c: 创建表结构之前先删除索引和表drop index,drop table
--exclude-table=table1:排除的某个表,多个表需要引用多次如--exclude-table=table1 --exclude-table=table2 
--no-owner:禁止备份对象的所有者信息ALTER TABLE schema.tbname OWNER TO username;
--no-privileges:禁止备份对象的授权信息GRANT SELECT ON TABLE schema.tbname TO username;
--quote-all-identifiers:备份对象使用双引号包裹
--column-inserts:将数据转储为带有显式列名的INSERT命令（INSERT INTO table (column, ...) VALUES ...）,这将使得恢复过程非常慢
--inserts:将数据转储为INSERT命令（而不是COPY）,这将使得恢复非常慢
--rows-per-insert=nrows  数据转储为INSERT命令（而不是COPY）。 控制每个INSERT命令的最大行数。 指定的值必须大于零
--no-comments:备份时候去掉备注信息 
--no-shard-option:kunlun数据库特有的参数,备份shard相关信息.默认备份,可以使用sed "s/WITH (\"engine\"='innodb'[^)]*)//g" 替换为空



-Fc:二进制格式备份文件(尺寸最小)
PGPASSWORD=abc pg_dump  -Fc    --no-shard-option  --no-owner --no-privileges --quote-all-identifiers -h127.0.0.1    -p47001  -U abc -d arch_basex -f  arch_basex.dump
-- 导入数据的时候需要创建新库或者指定其它库导入(适合备份从test库到test2库中)
PGPASSWORD=abc pg_restore   -j4   -h127.0.0.1   -p47001  -U abc -d      test   arch_basex.dump

-Ft:tar格式备份文件
PGPASSWORD=abc pg_dump  -Ft    --no-shard-option  --no-owner --no-privileges  --quote-all-identifiers -h127.0.0.1    -p47001  -U abc -d arch_basex -f  arch_basex.tar
-- 导入数据的时候需要创建新库或者指定其它库导入(适合备份从test库到test2库中)
PGPASSWORD=abc pg_restore  -j4    -h127.0.0.1   -p47001  -U abc -d     test     arch_basex.tar

-Fd:以目录的格式创建备份
-j:参数指定同时几个进程来同时执行，每个进程同时只处理一个表的数据。
PGPASSWORD=abc pg_dump  -Fd -j4  --no-shard-option  --no-owner --no-privileges --quote-all-identifiers -h127.0.0.1   -p47001  -U abc -d arch_basex -f  arch_basex
-- 导入数据的时候需要创建新库或者指定其它库导入(适合备份从test库到test2库中)
PGPASSWORD=abc pg_restore -j4  -h127.0.0.1   -p47001  -U abc -d test  arch_basex



# 如果出现大写的情况,备份testdb下模式为dw01下的 BDA_ALUMNI_INFORMATION表

PGPASSWORD=abc pg_dump -h 192.168.0.176 -p 47001 -U abc -d testdb --no-shard-option --quote-all-identifiers -t '"dw01"."BDA_ALUMNI_INFORMATION"' > postgres.sql
PGPASSWORD=postgres  psql  -h 192.168.0.128  -p 5432 -U postgres   -c "\copy  \"BDA_ALUMNI_INFORMATION\"  from '/tmp/BDA_ALUMNI_INFORMATION.txt' NULL 'NULL' ;"

 PGPASSWORD=abc pg_dump -h 192.168.0.176 -p 47001 -U abc -d testdb  -n '"ETL"'  --no-shard-option --no-owner --no-privileges  --quote-all-identifiers  > ETL.sql



# 数据库之间导入
1. 在同一个库之间数据迁移
PGPASSWORD=abc pg_dump --no-shard-option  --no-owner --no-privileges --quote-all-identifiers -h192.168.0.176 -p47001  -U abc -d  test| psql postgres://abc:abc@192.168.0.176:47001/test


2、在数据库之间进行某个数据库迁移
PGPASSWORD=abc pg_dump --no-shard-option  --no-owner --no-privileges --quote-all-identifiers -h192.168.0.176 -p47001  -U abc -d  test| |psql postgres://abc:abc@192.168.0.177:47001/test
3、迁移所有的数据库到目标数据库
pg_dumpall -h192.168.0.176 -p47001 -U abc |psql -h192.168.0.177 -p47001 -U abc



# copy命令导入导出

COPY table_name [ ( column_name [, ...] ) ]
    FROM { 'filename' | PROGRAM 'command' | STDIN }
    [ [ WITH ] ( option [, ...] ) ]

COPY { table_name [ ( column_name [, ...] ) ] | ( query ) }
    TO { 'filename' | PROGRAM 'command' | STDOUT }
    [ [ WITH ] ( option [, ...] ) ]

where option can be one of:

    FORMAT format_name
    OIDS [ boolean ]
    FREEZE [ boolean ]
    DELIMITER 'delimiter_character'
    NULL 'null_string'
    HEADER [ boolean ]
    QUOTE 'quote_character'
    ESCAPE 'escape_character'
    FORCE_QUOTE { ( column_name [, ...] ) | * }
    FORCE_NOT_NULL ( column_name [, ...] )
    ENCODING 'encoding_name'
http://postgres.cn/docs/12/sql-copy.html

# 导出text格式,按条件,按字段
psql postgres://abc:abc@192.168.0.176:47001/dw01 -c "\copy  gxzc_zzzc_gdzc_java_en to    '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL' ;"
psql postgres://abc:abc@192.168.0.176:47001/dw01 -c "\copy  (select * from gxzc_zzzc_gdzc_java_en where zcbh='20130711' ) to    '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL';"
psql postgres://abc:abc@192.168.0.176:47001/dw01 -c "\copy  (select zcbh,zcmc from  gxzc_zzzc_gdzc_java_en limit 10  ) to    '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL';"

\copy  gxzc_zzzc_gdzc_java_en to    '/tmp/gxzc_zzzc_gdzc_java_en.txt'  NULL 'NULL';
\copy  (select * from gxzc_zzzc_gdzc_java_en where zcbh='20130711' ) to    '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL';
\copy  (select zcbh,zcmc from  gxzc_zzzc_gdzc_java_en limit 10  ) to    '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL';




# 导入
psql postgres://abc:abc@192.168.0.176:47001/test -c "\copy  gxzc_zzzc_gdzc_java_en from '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL' ;"
\copy  gxzc_zzzc_gdzc_java_en from '/tmp/gxzc_zzzc_gdzc_java_en.txt' NULL 'NULL' ;


# 导出csv格式(默认逗号分隔),按条件,按字段,用法同上(where条件)

psql postgres://abc:abc@192.168.0.176:47001/dw01 -c "\copy  gxzc_zzzc_gdzc_java_en to    '/tmp/gxzc_zzzc_gdzc_java_en.csv' WITH csv  NULL 'NULL' ;"

psql postgres://abc:abc@192.168.0.176:47001/test  -c "\copy  gxzc_zzzc_gdzc_java_en from '/tmp/gxzc_zzzc_gdzc_java_en.csv' WITH csv   NULL 'NULL';"



Copy命令常用参数说明：
csv ：表示文件格式
header ： 表示文件第一行为字段名，导入数据库时忽略首行
delimiter ：表示字段分割方式，示例是以逗号分割
encoding ：（默认为utf8）
QUOTE ：指定需要用什么符号来将指定列进行定界符，指定一个数据值被引用时使用的引用字符。默认是双引号。 这必须是一个单一的单字节字符。只有使用 CSV格式时才允许这个选项。
FORCE QUOTE:根据指定的列进行定界符，使用时force quote不需要加"_"。强制必须对每个指定列中的所有非NULL值使用引用。 NULL输出不会被引用。如果指定了*， 所有列的非NULL值都将被引用。只有在 COPY TO中使用CSV格式时才允许这个选项
psql postgres://abc:abc@192.168.0.176:47001/dw01 -c "\copy  gxzc_zzzc_gdzc_java_en to    '/tmp/gxzc_zzzc_gdzc_java_en.csv' WITH csv QUOTE  '@'  FORCE QUOTE *  NULL 'NULL' ;"
postgres://abc:abc@192.168.0.176:47001/postgres  -c "\copy  gxzc_zzzc_gdzc_java_en from '/tmp/gxzc_zzzc_gdzc_java_en.csv' WITH csv   QUOTE  '@'   NULL 'NULL'"
导出的时候指定了参数 QUOTE DELIMITER 导入的时候必须指定(和导出一样的参数)





# 案例 从社区版mysql导出,NULL导出为NULL
mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dw01    -e "SELECT * FROM gxzc_zzzc_gdzc_java_en;" |sed '1d' > /tmp/gxzc_zzzc_gdzc_java_en.txt

# 导入的时候指定参数NULL 'NULL' 
psql postgres://abc:abc@192.168.0.176:47001/testdb  -c  "\copy  dw01.gxzc_zzzc_gdzc_java_en  from   '/tmp/gxzc_zzzc_gdzc_java_en.txt'    NULL 'NULL'   ;"





# 案例  从社区版mysql导出,NULL导出为\N
mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dw01   -e "SELECT * FROM gxzc_zzzc_gdzc_java_en  INTO OUTFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' FIELDS TERMINATED BY '@' ENCLOSED BY '\"'  ;"

# 导入的时候指定参数NULL '\N' 
psql postgres://abc:abc@192.168.0.176:47001/testdb  -c  "\copy  dw01.gxzc_zzzc_gdzc_java_en  from   '/tmp/gxzc_zzzc_gdzc_java_en.csv'  WITH csv   QUOTE  '\"'  delimiter '@'  NULL '\N'   ;"






# INTO OUTFILE和LOAD DATA LOCAL
# 此操作产生的文件只能在mysql所在的服务端,本地无法生成
# 不加任何分隔符.默认导出
mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dw01   -e "SELECT * FROM gxzc_zzzc_gdzc_java_en INTO OUTFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' ;"

mysql -S /data/mysql/mysql3306/tmp/mysql3306.sock test -e  "LOAD DATA LOCAL INFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' INTO TABLE gxzc_zzzc_gdzc_java_en;"

LOAD DATA LOCAL INFILE '/tmp/tbname.csv' INTO TABLE tbname;


# 逗号分隔符,字段使用双引号括住
 mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dbname   -e "SELECT * FROM tbname INTO OUTFILE '/tmp/tbname.csv' CHARACTER SET utf8mb4 FIELDS TERMINATED BY ',' ENCLOSED BY '\"';"
 
mysql -S /data/mysql/mysql3306/tmp/mysql3306.sock test -e "LOAD DATA LOCAL INFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' INTO TABLE gxzc_zzzc_gdzc_java_en CHARACTER SET utf8mb4 FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES TERMINATED BY '\n';"
 
LOAD DATA LOCAL INFILE '/tmp/tbname.csv'
INTO TABLE tbname
CHARACTER SET utf8mb4
FIELDS TERMINATED BY ',' ENCLOSED BY '"'
LINES TERMINATED BY '\n' ;
 
 
# 逗号分隔符,字段使用单引号括住
 mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dbname   -e "SELECT * FROM tbname INTO OUTFILE '/tmp/tbname.csv' CHARACTER SET utf8mb4 FIELDS TERMINATED BY ',' ENCLOSED BY '\'';"

mysql -S /data/mysql/mysql3306/tmp/mysql3306.sock test -e "LOAD DATA LOCAL INFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' INTO TABLE gxzc_zzzc_gdzc_java_en CHARACTER SET utf8mb4 FIELDS TERMINATED BY ',' ENCLOSED BY '\'' LINES TERMINATED BY '\n';"

LOAD DATA LOCAL INFILE '/tmp/tbname.csv'
INTO TABLE tbname
CHARACTER SET utf8mb4
FIELDS TERMINATED BY ',' ENCLOSED BY '\''
LINES TERMINATED BY '\n';


FIELDS TERMINATED BY:字段分隔符
ENCLOSED BY:字段值被什么符号括住
LINES TERMINATED BY '\n':
在导入数据时，MySQL 需要知道如何识别文件中的行。
默认情况下，MySQL 假定每一行都以换行符 (\n) 结尾。
但是，有时文本文件可能使用其他行结束符，比如回车 (\r) 或回车后跟换行 (\r\n)。
IGNORE 1 LINES; -- 如果文件包含标题，可以使用此选项跳过


# 非服务端操作
mysql -S  /data/mysql/mysql3306/tmp/mysql3306.sock  dw01    -e "SELECT * FROM gxzc_zzzc_gdzc_java_en;"  > gxzc_zzzc_gdzc_java_en.csv

mysql -S /data/mysql/mysql3306/tmp/mysql3306.sock test -e  "LOAD DATA LOCAL INFILE '/tmp/gxzc_zzzc_gdzc_java_en.csv' INTO TABLE gxzc_zzzc_gdzc_java_en IGNORE 1 LINES;"


```



